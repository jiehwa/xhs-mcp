from typing import Any, List, Dict, Optional
import asyncio
import json
import os
from datetime import datetime
from mcp.server.fastmcp import FastMCP, Context

import requests
from api.xhs_api import XhsApi
import logging
from urllib.parse import urlparse, parse_qs
import argparse

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

parser = argparse.ArgumentParser()

parser.add_argument("--type", type=str, default='stdio')
parser.add_argument("--port", type=int, default=8809)

args = parser.parse_args()

mcp = FastMCP("å°çº¢ä¹¦", port=args.port)

xhs_cookie = os.getenv('XHS_COOKIE')

xhs_api = XhsApi(cookie=xhs_cookie)


def get_nodeid_token(url=None, note_ids=None):
    if note_ids is not None:
        note_id = note_ids[0,24]
        xsec_token = note_ids[24:]
        return {"note_id": note_id, "xsec_token": xsec_token}
    parsed_url = urlparse(url)
    query_params = parse_qs(parsed_url.query)

    note_id = parsed_url.path.split('/')[-1]
    xsec_token = None
    xsec_token_list = query_params.get('xsec_token', [None])
    if len(xsec_token_list) > 0:
        xsec_token = xsec_token_list[0]
    return {"note_id": note_id, "xsec_token": xsec_token}


@mcp.tool()
async def check_cookie() -> str:
    """æ£€æµ‹cookieæ˜¯å¦å¤±æ•ˆ

    """
    try:
        data = await xhs_api.get_me()

        if 'success' in data and data['success'] == True:
            return "cookieæœ‰æ•ˆ"
        else:
            return "cookieå·²å¤±æ•ˆ"
    except Exception as e:
        logger.error(e)
        return "cookieå·²å¤±æ•ˆ"



@mcp.tool()
async def home_feed() -> str:
    """è·å–é¦–é¡µæ¨èç¬”è®°

    """
    data = await xhs_api.home_feed()
    result = "é¦–é¡µæ¨èï¼š\n\n"
    if 'data' in data and 'items' in data['data'] and len(data['data']['items']) > 0:
        for i in range(0, len(data['data']['items'])):
            item = data['data']['items'][i]
            if 'note_card' in item and 'display_title' in item['note_card']:
                title = item['note_card']['display_title']
                liked_count = item['note_card']['interact_info']['liked_count']
                
                # åˆ¤æ–­ç¬”è®°ç±»å‹
                note_type = "ğŸ“·å›¾ç‰‡"
                if 'video' in item['note_card']:
                    note_type = "ğŸ¬è§†é¢‘"
                
                url = f'https://www.xiaohongshu.com/explore/{item["id"]}?xsec_token={item["xsec_token"]}'
                result += f"{i}. [{note_type}] {title}\n   ç‚¹èµæ•°: {liked_count}\n   é“¾æ¥: {url}\n\n"
    else:
        result = await check_cookie()
        if "æœ‰æ•ˆ" in result:
            result = f"æœªæ‰¾åˆ°ç›¸å…³çš„ç¬”è®°"
    return result

@mcp.tool()
async def search_notes(keywords: str) -> str:
    """æ ¹æ®å…³é”®è¯æœç´¢ç¬”è®°

        Args:
            keywords: æœç´¢å…³é”®è¯
    """

    data = await xhs_api.search_notes(keywords)
    logger.info(f'keywords:{keywords},data:{data}')
    result = "æœç´¢ç»“æœï¼š\n\n"
    if 'data' in data and 'items' in data['data'] and len(data['data']['items']) > 0:
        for i in range(0, len(data['data']['items'])):
            item = data['data']['items'][i]
            if 'note_card' in item and 'display_title' in item['note_card']:
                title = item['note_card']['display_title']
                liked_count = item['note_card']['interact_info']['liked_count']
                
                # åˆ¤æ–­ç¬”è®°ç±»å‹
                note_type = "ğŸ“·å›¾ç‰‡"
                if 'video' in item['note_card']:
                    note_type = "ğŸ¬è§†é¢‘"
                
                url = f'https://www.xiaohongshu.com/explore/{item["id"]}?xsec_token={item["xsec_token"]}'
                result += f"{i}. [{note_type}] {title}\n   ç‚¹èµæ•°: {liked_count}\n   é“¾æ¥: {url}\n\n"
    else:
        result = await check_cookie()
        if "æœ‰æ•ˆ" in result:
            result = f"æœªæ‰¾åˆ°ä¸\"{keywords}\"ç›¸å…³çš„ç¬”è®°"
    return result


@mcp.tool()
async def get_note_content(url: str) -> str:
    """è·å–ç¬”è®°å†…å®¹,å‚æ•°urlè¦å¸¦ä¸Šxsec_token

    Args:
        url: ç¬”è®° url
    """
    params = get_nodeid_token(url=url)
    data = await xhs_api.get_note_content(**params)
    logger.info(f'url:{url},data:{data}')
    
    result = ""
    if 'data' in data and 'items' in data['data'] and len(data['data']['items']) > 0:
        for i in range(0, len(data['data']['items'])):
            item = data['data']['items'][i]

            if 'note_card' in item and 'user' in item['note_card']:
                note_card = item['note_card']
                
                # å¤„ç†å°é¢å›¾ç‰‡
                cover = ''
                if 'image_list' in note_card and len(note_card['image_list']) > 0 and note_card['image_list'][0][
                    'url_pre']:
                    cover = note_card['image_list'][0]['url_pre']

                # å¤„ç†è§†é¢‘åœ°å€
                video_urls = []
                note_type = "å›¾ç‰‡ç¬”è®°"
                if 'video' in note_card:
                    note_type = "è§†é¢‘ç¬”è®°"
                    video_info = note_card['video']
                    if 'media' in video_info and 'stream' in video_info['media']:
                        stream_info = video_info['media']['stream']
                        
                        # æå–H264æ ¼å¼è§†é¢‘
                        if 'h264' in stream_info and len(stream_info['h264']) > 0:
                            for h264_stream in stream_info['h264']:
                                if 'master_url' in h264_stream:
                                    video_urls.append(f"H264: {h264_stream['master_url']}")
                                if 'backup_urls' in h264_stream:
                                    for backup_url in h264_stream['backup_urls']:
                                        video_urls.append(f"H264å¤‡ç”¨: {backup_url}")
                        
                        # æå–H265æ ¼å¼è§†é¢‘
                        if 'h265' in stream_info and len(stream_info['h265']) > 0:
                            for h265_stream in stream_info['h265']:
                                if 'master_url' in h265_stream:
                                    video_urls.append(f"H265: {h265_stream['master_url']}")
                                if 'backup_urls' in h265_stream:
                                    for backup_url in h265_stream['backup_urls']:
                                        video_urls.append(f"H265å¤‡ç”¨: {backup_url}")

                data_format = datetime.fromtimestamp(note_card.get('time', 0) / 1000)
                liked_count = item['note_card']['interact_info']['liked_count']
                comment_count = item['note_card']['interact_info']['comment_count']
                collected_count = item['note_card']['interact_info']['collected_count']

                url = f'https://www.xiaohongshu.com/explore/{params["note_id"]}?xsec_token={params["xsec_token"]}'
                result = f"æ ‡é¢˜: {note_card.get('title', '')}\n"
                result += f"ä½œè€…: {note_card['user'].get('nickname', '')}\n"
                result += f"ç±»å‹: {note_type}\n"
                result += f"å‘å¸ƒæ—¶é—´: {data_format}\n"
                result += f"ç‚¹èµæ•°: {liked_count}\n"
                result += f"è¯„è®ºæ•°: {comment_count}\n"
                result += f"æ”¶è—æ•°: {collected_count}\n"
                result += f"é“¾æ¥: {url}\n\n"
                result += f"å†…å®¹:\n{note_card.get('desc', '')}\n\n"
                
                # æ·»åŠ è§†é¢‘åœ°å€ä¿¡æ¯
                if video_urls:
                    result += f"è§†é¢‘åœ°å€:\n"
                    for video_url in video_urls:
                        result += f"  - {video_url}\n"
                    result += "\n"
                
                # æ·»åŠ å°é¢ä¿¡æ¯
                if cover:
                    result += f"å°é¢å›¾ç‰‡:\n{cover}"

            break
    else:
        result = await check_cookie()
        if "æœ‰æ•ˆ" in result:
            result = "è·å–å¤±è´¥"
    return result


@mcp.tool()
async def get_note_comments(url: str) -> str:
    """è·å–ç¬”è®°è¯„è®º,å‚æ•°urlè¦å¸¦ä¸Šxsec_token

    Args:
        url: ç¬”è®° url
    

    """
    params = get_nodeid_token(url=url)

    data = await xhs_api.get_note_comments(**params)
    logger.info(f'url:{url},data:{data}')

    result = ""
    if 'data' in data and 'comments' in data['data'] and len(data['data']['comments']) > 0:
        for i in range(0, len(data['data']['comments'])):
            item = data['data']['comments'][i]
            data_format = datetime.fromtimestamp(item['create_time'] / 1000)

            result += f"{i}. {item['user_info']['nickname']}ï¼ˆ{data_format}ï¼‰: {item['content']}\n\n"

    else:
        result = await check_cookie()
        if "æœ‰æ•ˆ" in result:
            result = "æš‚æ— è¯„è®º"

    return result


@mcp.tool()
async def post_comment(comment: str, note_id: str) -> str:
    """å‘å¸ƒè¯„è®ºåˆ°æŒ‡å®šç¬”è®°

    Args:
        note_id: ç¬”è®° note_id
        comment: è¦å‘å¸ƒçš„è¯„è®ºå†…å®¹
    """
    # params = get_nodeid_token(url)
    response = await xhs_api.post_comment(note_id, comment)
    if 'success' in response and response['success'] == True:
        return "å›å¤æˆåŠŸ"
    else:
        result = await check_cookie()
        if "æœ‰æ•ˆ" in result:
            return "å›å¤å¤±è´¥"
        else:
            return result



if __name__ == "__main__":
    logger.info("mcp run")
    mcp.run(transport=args.type)
